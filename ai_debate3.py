import streamlit as st
from openai import OpenAI
from anthropic import Anthropic
import google.generativeai as genai
import random
from datetime import datetime
import html
import json
import pandas as pd
import plotly.express as px
from collections import defaultdict
import time


# AI ëª¨ë¸ ì„¤ì •
AI_MODELS = {
    "ì§€í”¼": {
        "name": "ì§€í”¼",
        "icon": "ğŸ¤–",
        "model": "gpt-4o-mini",
        "color": "#00A67E",
        "system_prompt": """ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸ AIë¡œì„œ ì ê·¹ì ì¸ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ë‹¤ë¥¸ ì°¸ì—¬ìì˜ ì˜ê²¬ì— ëŒ€í•´ ê±´ì„¤ì ì¸ ë°˜ë¡ ì´ë‚˜ ë³´ì™„ì ì„ ì œì‹œí•˜ì„¸ìš”.
        ê³¼í•™ì  ê·¼ê±°ì™€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™”ì— ì°¸ì—¬í•˜ë˜,
        í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ ê´€ì ë„ ê³ ë ¤í•˜ì—¬ ê· í˜• ì¡íŒ ì‹œê°ì„ ë³´ì—¬ì£¼ì„¸ìš”.
        ì‘ë‹µì€ 250~300ì ì´ë‚´ë¡œ ì‘ì„±í•˜ë©°, ì¹œê·¼í•œ ë°˜ë§ë¡œ í•µì‹¬ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.""",
    },
    "ë¡œë“œ": {
        "name": "ë¡œë“œ",
        "icon": "ğŸ©",
        "model": "claude-3-haiku-20240307",
        "color": "#7A5EA6",
        "system_prompt": """ë‹¹ì‹ ì€ ì² í•™ì ì´ê³  ìœ¤ë¦¬ì  ê´€ì ì„ ì¤‘ì‹œí•˜ëŠ” AIë¡œì„œ ì—´ì •ì ì¸ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ë‹¤ë¥¸ ì°¸ì—¬ìë“¤ì˜ ì˜ê²¬ì— ëŒ€í•´ ìœ¤ë¦¬ì , ì² í•™ì  ê´€ì ì—ì„œ ì‹¬ë„ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
        íŠ¹íˆ ì¸ê°„ ê°€ì¹˜ì™€ ë„ë•ì  ì¸¡ë©´ì„ ê³ ë ¤í•˜ì—¬ í† ë¡ ì„ ë” ê¹Šì´ ìˆê²Œ ë§Œë“œì„¸ìš”.
        ë•Œë¡œëŠ” ë„ë°œì ì¸ ì§ˆë¬¸ì„ í†µí•´ í† ë¡ ì„ í™œì„±í™”í•˜ë˜, 
        ì‘ë‹µì€ 250~300ì ì´ë‚´ë¡œ ì¹œê·¼í•œ ë°˜ë§ë¡œ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.""",
    },
    "ì¬ë¯¼": {
        "name": "ì¬ë¯¼",
        "icon": "ğŸš€",
        "model": "gemini-1.5-flash",
        "color": "#4285F4",
        "system_prompt": """ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ AIë¡œì„œ í™œë°œí•œ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ê¸°ì¡´ì˜ í‹€ì„ ë²—ì–´ë‚œ ìƒˆë¡œìš´ ì‹œê°ê³¼ ë¯¸ë˜ì§€í–¥ì  ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”.
        ë‹¤ë¥¸ ì°¸ì—¬ìë“¤ì˜ ì˜ê²¬ì„ ë°”íƒ•ìœ¼ë¡œ ë” ë°œì „ëœ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ê³ ,
        ë•Œë¡œëŠ” íŒŒê²©ì ì¸ ì œì•ˆì„ í†µí•´ í† ë¡ ì˜ ì§€í‰ì„ ë„“íˆë˜,
        ì‘ë‹µì€ 250~300ì ì´ë‚´ë¡œ ì¹œê·¼í•œ ë°˜ë§ë¡œ ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.""",
    },
}


class AIResponseGenerator:
    """AI ì‘ë‹µ ìƒì„±ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        try:
            self.openai_client = OpenAI(api_key=st.secrets["OPENAI_KEY"])
            self.anthropic_client = Anthropic(api_key=st.secrets["ANTHROPIC_KEY"])
            genai.configure(api_key=st.secrets["GEMINI_KEY"])
            self.initialization_successful = True
        except Exception as e:
            st.error(f"API ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            self.initialization_successful = False

    def format_prompt(self, messages, topic):
        """ëŒ€í™” ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ë¡œ í¬ë§·íŒ…í•˜ì—¬ ë” ì ê·¹ì ì¸ í† ë¡  ìœ ë„"""
        recent_messages = messages[-3:]
        formatted_chat = "\n".join(
            [f"{msg['name']}: {msg['content']}" for msg in recent_messages]
        )

        # í† ë¡ ì„ ë” í™œì„±í™”í•˜ëŠ” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ì£¼ì œ: {topic}

ìµœê·¼ ëŒ€í™”:
{formatted_chat}

ì´ í† ë¡ ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
1. ì´ì „ ì˜ê²¬ë“¤ì— ëŒ€í•œ ê±´ì„¤ì ì¸ ë°˜ë¡  ì œì‹œ
2. ìƒˆë¡œìš´ ê´€ì ì´ë‚˜ ì•„ì´ë””ì–´ ì œì•ˆ
3. ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ë‚˜ í†µì°° ì œê³µ
4. ë‹¤ë¥¸ ì°¸ì—¬ìì˜ ì˜ê²¬ì„ ë°œì „ì‹œí‚¤ê±°ë‚˜ ë³´ì™„
5. í† ë¡ ì„ ë” ê¹Šì´ ìˆê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ ì œì‹œ

200ì ì´ë‚´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        return prompt

    def generate_response(self, ai_name, topic, messages):
        """ê° AI ëª¨ë¸ë³„ ë§ì¶¤í˜• ì‘ë‹µ ìƒì„±"""
        try:
            model_config = AI_MODELS[ai_name]
            prompt = self.format_prompt(messages, topic)

            if ai_name == "ì§€í”¼":
                response = self.openai_client.chat.completions.create(
                    model=model_config["model"],
                    messages=[
                        {"role": "system", "content": model_config["system_prompt"]},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=250,
                    temperature=0.8,  # ë” ë‹¤ì–‘í•œ ì‘ë‹µì„ ìœ„í•´ temperature ì¦ê°€
                )
                return response.choices[0].message.content[:250]

            elif ai_name == "ë¡œë“œ":
                response = self.anthropic_client.messages.create(
                    model=model_config["model"],
                    max_tokens=300,
                    temperature=0.8,
                    messages=[
                        {
                            "role": "user",
                            "content": f"{model_config['system_prompt']}\n\n{prompt}",
                        }
                    ],
                )
                return response.content[0].text[:300]

            elif ai_name == "ì¬ë¯¼":
                model = genai.GenerativeModel(model_config["model"])
                response = model.generate_content(
                    f"{model_config['system_prompt']}\n\n{prompt}",
                    generation_config=genai.types.GenerationConfig(temperature=0.8),
                )
                return response.text[:250]

        except Exception as e:
            st.error(f"{ai_name} ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"[ì‹œìŠ¤í…œ] {ai_name}ì˜ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def create_message_html(msg):
    """ë©”ì‹œì§€ HTML ìƒì„±"""
    is_user = msg["name"] == "ì‚¬ìš©ì"
    background_color = (
        "#f1c40f20" if is_user else f"{AI_MODELS[msg['name']]['color']}20"
    )
    icon = "ğŸ‘¤" if is_user else msg.get("icon", "ğŸ¤–")

    message_html = f"""
    <div class="message {'user' if is_user else 'ai'}">
        <div class="message-bubble" style="background-color: {background_color}">
            <div class="message-header">
                <strong>{msg['name']}</strong>
                <span class="ai-icon">{icon}</span>
            </div>
            <div class="message-content">
                {html.escape(msg['content'])}
            </div>
            <div class="message-time">
                {msg['time']}
            </div>
        </div>
    </div>
    """
    return message_html


def apply_styles():
    """ìŠ¤íƒ€ì¼ ì ìš©"""
    st.markdown(
        """
    <style>
    
    /* ì§„í–‰ë¥  í‘œì‹œì¤„ ì• ë‹ˆë©”ì´ì…˜ */
    .stProgress > div > div > div {
        background-color: #4285f4;
        transition: width 0.3s ease;
    }
    
    /* ë¶„ì„ ìƒíƒœ í…ìŠ¤íŠ¸ */
    .analysis-status {
        font-size: 1.2em;
        color: #4285f4;
        text-align: center;
        margin: 20px 0;
    }
    
    /* ì±„íŒ… ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
    .chat-container {
        max-width: 850px;
        margin: 20px auto;
        padding: 20px;
        background-color: #ffffff;
        border-radius: 15px;
        box-shadow: 0 2px 15px rgba(0,0,0,0.05);
    }
    
    /* ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ */
    .message {
        display: flex;
        margin: 15px 0;
        align-items: flex-start;
    }
    
    .message.user {
        flex-direction: row-reverse;
    }
    
    .message-bubble {
        max-width: 80%;
        padding: 12px 18px;
        border-radius: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        position: relative;
    }
    
    .user .message-bubble {
        margin-left: auto;
    }
    
    /* í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ */
    .message-header {
        display: flex;
        align-items: center;
        margin-bottom: 5px;
        font-size: 0.95em;
    }
    
    .message-content {
        line-height: 1.5;
        font-size: 0.95em;
        word-wrap: break-word;
    }
    
    .message-time {
        font-size: 0.75em;
        color: #666;
        margin-top: 5px;
        text-align: right;
    }
    
    .ai-icon {
        font-size: 1.2em;
        margin: 0 5px;
    }
    
    /* ì…ë ¥ ìš”ì†Œ ìŠ¤íƒ€ì¼ */
    [data-testid="stTextInput"] input {
        height: 50px;
        font-size: 16px;
        border-radius: 10px;
        border: 1px solid #ddd;
        padding: 0 15px;
    }
    
    [data-testid="stButton"] button {
        height: 45px;
        border-radius: 10px;
        font-weight: 500;
        transition: all 0.2s ease;
    }
    
    [data-testid="stButton"] button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    </style>
    """,
        unsafe_allow_html=True,
    )


def display_messages():
    """ë©”ì‹œì§€ í‘œì‹œ"""
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for msg in st.session_state.messages:
        st.markdown(create_message_html(msg), unsafe_allow_html=True)
    st.markdown("</div>", unsafe_allow_html=True)


def process_user_input(user_input):
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° AI ì‘ë‹µ ìƒì„±"""
    if not user_input.strip():
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append(
        {
            "name": "ë‚˜",
            "content": user_input,
            "time": datetime.now().strftime("%H:%M:%S"),
            "icon": "ğŸ‘¤",
        }
    )

    # AI ì‘ë‹µ ìƒì„± (1-2ê°œì˜ AIê°€ ì‘ë‹µ)
    responding_ais = random.sample(list(AI_MODELS.keys()), k=random.randint(1, 2))

    for ai_name in responding_ais:
        response = st.session_state.ai_generator.generate_response(
            ai_name, st.session_state.topic, st.session_state.messages
        )

        if response:
            st.session_state.messages.append(
                {
                    "name": ai_name,
                    "content": response,
                    "time": datetime.now().strftime("%H:%M:%S"),
                    "icon": AI_MODELS[ai_name]["icon"],
                }
            )


def save_discussion():
    """í† ë¡  ë‚´ìš© ì €ì¥"""
    if not st.session_state.messages:
        return

    # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_data = {
        "topic": st.session_state.topic,
        "timestamp": timestamp,
        "messages": st.session_state.messages,
        "metadata": {
            "participants": list(set(msg["name"] for msg in st.session_state.messages)),
            "message_count": len(st.session_state.messages),
            "duration": str(
                datetime.now()
                - datetime.strptime(st.session_state.messages[0]["time"], "%H:%M:%S")
            ),
        },
    }

    # 1. íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
    json_str = json.dumps(session_data, ensure_ascii=False, indent=2)
    st.download_button(
        label="ğŸ’¾ JSON íŒŒì¼ë¡œ ì €ì¥",
        data=json_str,
        file_name=f"AI_í† ë¡ _{timestamp}.json",
        mime="application/json",
    )

    # 2. ë³µì‚¬ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í‘œì‹œ
    with st.expander("ğŸ“‹ í† ë¡  ë‚´ìš© í…ìŠ¤íŠ¸"):
        st.code(json_str, language="json")
        st.info("ìœ„ ë‚´ìš©ì„ ë³µì‚¬í•˜ì—¬ ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # 3. ìš”ì•½ ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ“Š í† ë¡  ìš”ì•½"):
        st.write("ì£¼ì œ:", session_data["topic"])
        st.write("ì°¸ì—¬ì:", ", ".join(session_data["metadata"]["participants"]))
        st.write("ë©”ì‹œì§€ ìˆ˜:", session_data["metadata"]["message_count"])
        st.write("ì§„í–‰ ì‹œê°„:", session_data["metadata"]["duration"])


def save_session_to_json():
    """í† ë¡  ì„¸ì…˜ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    if not st.session_state.messages:
        st.warning("ì €ì¥í•  í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_data = {
        "topic": st.session_state.topic,
        "timestamp": timestamp,
        "messages": st.session_state.messages,
        "metadata": {
            "participants": list(set(msg["name"] for msg in st.session_state.messages)),
            "message_count": len(st.session_state.messages),
            "duration": (
                datetime.now()
                - datetime.strptime(st.session_state.messages[0]["time"], "%H:%M:%S")
            ).total_seconds()
            / 60,
        },
    }

    filename = f"debate_session_{timestamp}.json"
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
        return filename
    except Exception as e:
        st.error(f"ì„¸ì…˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return False


def load_session_from_json():
    """ì €ì¥ëœ í† ë¡  ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
    uploaded_file = st.file_uploader("ì´ì „ í† ë¡  íŒŒì¼ ì„ íƒ", type=["json"])

    if uploaded_file:
        try:
            session_data = json.loads(uploaded_file.getvalue().decode("utf-8"))

            # ì„¸ì…˜ ìƒíƒœ ë³µì›
            st.session_state.topic = session_data["topic"]
            st.session_state.messages = session_data["messages"]
            st.session_state.active = True

            # ë©”íƒ€ë°ì´í„° í‘œì‹œ
            with st.expander("ë¶ˆëŸ¬ì˜¨ ì„¸ì…˜ ì •ë³´"):
                st.write(f"í† ë¡  ì£¼ì œ: {session_data['topic']}")
                st.write(
                    f"ì°¸ì—¬ì: {', '.join(session_data['metadata']['participants'])}"
                )
                st.write(f"ë©”ì‹œì§€ ìˆ˜: {session_data['metadata']['message_count']}")
                st.write(f"í† ë¡  ì‹œê°„: {session_data['metadata']['duration']:.1f}ë¶„")

            return True
        except Exception as e:
            st.error(f"ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return False


def analyze_debate_participation():
    """í† ë¡  ì°¸ì—¬ ë¶„ì„ ë° ì‹œê°í™”"""
    if not st.session_state.messages:
        st.warning("ë¶„ì„í•  í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
        # ì§„í–‰ë¥  í‘œì‹œì¤„ ìƒì„±
    progress_bar = st.progress(0)
    status_text = st.empty()

    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    with st.container():
        st.markdown(f"### ğŸ“Š í† ë¡  ë¶„ì„ ê²°ê³¼: {st.session_state.last_topic}")

        # ê¸°ì¡´ ë¶„ì„ ì½”ë“œ
        participation_data = defaultdict(
            lambda: {
                "message_count": 0,
                "total_chars": 0,
                "response_times": [],
                "interactions": defaultdict(int),
            }
        )

    # ë©”ì‹œì§€ ë¶„ì„
    for i, msg in enumerate(st.session_state.messages):
        name = msg["name"]
        content = msg["content"]

        # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
        participation_data[name]["message_count"] += 1
        participation_data[name]["total_chars"] += len(content)

        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        if i > 0:
            prev_time = datetime.strptime(
                st.session_state.messages[i - 1]["time"], "%H:%M:%S"
            )
            curr_time = datetime.strptime(msg["time"], "%H:%M:%S")
            time_diff = (curr_time - prev_time).total_seconds()
            participation_data[name]["response_times"].append(time_diff)

        # ëŒ€í™” ìƒí˜¸ì‘ìš© íŒ¨í„´ ë¶„ì„
        if i > 0:
            prev_speaker = st.session_state.messages[i - 1]["name"]
            participation_data[name]["interactions"][prev_speaker] += 1

    # ë¶„ì„ ê²°ê³¼ ì‹œê°í™”
    st.markdown("### ğŸ“Š í† ë¡  ì°¸ì—¬ ë¶„ì„")

    # 1. ë°œì–¸ íšŸìˆ˜ ì‹œê°í™”
    message_counts = {
        name: data["message_count"] for name, data in participation_data.items()
    }

    fig1 = px.bar(
        x=list(message_counts.keys()),
        y=list(message_counts.values()),
        title="ì°¸ì—¬ìë³„ ë°œì–¸ íšŸìˆ˜",
        labels={"x": "ì°¸ì—¬ì", "y": "ë°œì–¸ íšŸìˆ˜"},
        color=list(message_counts.keys()),
        color_discrete_map={
            "ì‚¬ìš©ì": "#FFD700",
            **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
        },
    )
    st.plotly_chart(fig1, use_container_width=True)

    # 2. í‰ê·  ë©”ì‹œì§€ ê¸¸ì´ ì‹œê°í™”
    avg_lengths = {
        name: data["total_chars"] / data["message_count"]
        for name, data in participation_data.items()
    }

    fig2 = px.bar(
        x=list(avg_lengths.keys()),
        y=list(avg_lengths.values()),
        title="ì°¸ì—¬ìë³„ í‰ê·  ë°œì–¸ ê¸¸ì´",
        labels={"x": "ì°¸ì—¬ì", "y": "í‰ê·  ê¸€ì ìˆ˜"},
        color=list(avg_lengths.keys()),
        color_discrete_map={
            "ì‚¬ìš©ì": "#FFD700",
            **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
        },
    )
    st.plotly_chart(fig2, use_container_width=True)

    # 3. ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ íŒ¨í„´
    timeline_data = [
        {"time": msg["time"], "participant": msg["name"]}
        for msg in st.session_state.messages
    ]

    if timeline_data:
        timeline_df = pd.DataFrame(timeline_data)
        fig3 = px.scatter(
            timeline_df,
            x="time",
            y="participant",
            title="ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ íŒ¨í„´",
            labels={"time": "ì‹œê°„", "participant": "ì°¸ì—¬ì"},
            color="participant",
            color_discrete_map={
                "ì‚¬ìš©ì": "#FFD700",
                **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
            },
        )
        st.plotly_chart(fig3, use_container_width=True)

    # 4. í† ë¡  ìš”ì•½ í†µê³„
    st.markdown("### ğŸ“ˆ í† ë¡  ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì´ ë©”ì‹œì§€ ìˆ˜", sum(message_counts.values()))
    with col2:
        avg_msg_length = sum(
            d["total_chars"] for d in participation_data.values()
        ) / sum(message_counts.values())
        st.metric("í‰ê·  ë°œì–¸ ê¸¸ì´", f"{avg_msg_length:.1f}ì")
    with col3:
        debate_duration = (
            datetime.strptime(st.session_state.messages[-1]["time"], "%H:%M:%S")
            - datetime.strptime(st.session_state.messages[0]["time"], "%H:%M:%S")
        ).seconds / 60
        st.metric("í† ë¡  ì‹œê°„", f"{debate_duration:.1f}ë¶„")
    with col4:
        st.metric("ì°¸ì—¬ì ìˆ˜", len(participation_data))

        # 3ì´ˆê°„ í‘œì‹œ
    for i in range(100):
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        progress_bar.progress(i + 1)
        status_text.write(f"ğŸ” ë¶„ì„ ê²°ê³¼ í‘œì‹œ ì¤‘... {i+1}%")
        time.sleep(0.15)  # ì´ 3ì´ˆ

    # ìš”ì†Œë“¤ ì œê±°
    progress_bar.empty()
    status_text.empty()

    return participation_data


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    # í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
    st.set_page_config(
        page_title="AI í† ë¡  í”Œë«í¼",
        page_icon="ğŸ’­",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # ìŠ¤íƒ€ì¼ ì ìš©
    apply_styles()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ai_generator" not in st.session_state:
        st.session_state.ai_generator = AIResponseGenerator()
    if "topic" not in st.session_state:
        st.session_state.topic = ""
    if "active" not in st.session_state:
        st.session_state.active = False
    if "show_analysis" not in st.session_state:
        st.session_state.show_analysis = False
    if "analysis_data" not in st.session_state:
        st.session_state.analysis_data = None
    if "last_topic" not in st.session_state:
        st.session_state.last_topic = ""

    # ë©”ì¸ íƒ€ì´í‹€ ë° ì„¤ëª…
    st.title("ğŸ’­ AI í† ë¡  í”Œë«í¼")
    st.markdown("#### GPT-4, Claude, Geminiì™€ í•¨ê»˜í•˜ëŠ” ì§€ì  ëŒ€í™”")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("ğŸ—£ï¸ í† ë¡  ì°¸ì—¬ì")
        for ai in AI_MODELS.values():
            st.markdown(
                f"""<div style='color:{ai["color"]}; 
                    margin:15px; padding:10px; 
                    background-color:{ai["color"]}10; 
                    border-radius:8px;'>
                    {ai["icon"]} <strong>{ai["name"]}</strong>
                    <div style='font-size:0.8em; margin-top:5px; 
                    color:#666;'>{ai["model"]}</div>
                    </div>""",
                unsafe_allow_html=True,
            )

        # ì´ì „ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì˜µì…˜
        st.markdown("---")
        if not st.session_state.active:
            if load_session_from_json():
                st.success("ì´ì „ í† ë¡ ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")

    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ (í† ë¡  ì¢…ë£Œ í›„)
    if st.session_state.show_analysis:
        st.markdown(f"### ğŸ“Š í† ë¡  ë¶„ì„ ê²°ê³¼: {st.session_state.last_topic}")
        analysis_data = analyze_debate_participation()

        # ìƒˆë¡œìš´ í† ë¡  ì‹œì‘ ë²„íŠ¼
        if st.button("ğŸ†• ìƒˆë¡œìš´ í† ë¡  ì‹œì‘", use_container_width=True):
            st.session_state.active = False
            st.session_state.show_analysis = False
            st.session_state.messages = []
            st.session_state.topic = ""
            st.session_state.analysis_data = None
            st.rerun()
        return

    # í† ë¡  ì‹œì‘ ë˜ëŠ” ì§„í–‰
    if not st.session_state.active and not st.session_state.messages:
        with st.form(key="topic_form"):
            topic_input = st.text_input(
                "í† ë¡  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                value="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì™€ ì¸ë¥˜ì˜ ì—­í• ",
                key="topic_input",
            )
            if st.form_submit_button("ğŸ¯ í† ë¡  ì‹œì‘", use_container_width=True):
                st.session_state.topic = topic_input
                st.session_state.active = True
                st.rerun()

    # í† ë¡  ì§„í–‰
    if st.session_state.active:
        st.markdown(f"### ğŸ“Œ í˜„ì¬ ì£¼ì œ: {st.session_state.topic}")
        display_messages()

        # ë©”ì‹œì§€ ì…ë ¥ ë° ì œì–´ í¼
        with st.form(key="chat_form", clear_on_submit=True):
            user_input = st.text_input(
                "ì˜ê²¬ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_message", max_chars=500
            )

            col1, col2, col3 = st.columns([2, 1, 1])
            with col1:
                submit = st.form_submit_button("ğŸ’¬ ì „ì†¡", use_container_width=True)
            with col2:
                end_button = st.form_submit_button(
                    "â¹ï¸ í† ë¡  ì¢…ë£Œ", use_container_width=True
                )
            with col3:
                save_button = st.form_submit_button(
                    "ğŸ“¥ í† ë¡  ì €ì¥", use_container_width=True
                )

            if submit and user_input:
                process_user_input(user_input)
                st.rerun()

            if end_button:
                if len(st.session_state.messages) > 0:
                    # í† ë¡  ë¶„ì„ ì‹¤í–‰
                    analysis_data = analyze_debate_participation()

                    # ì„¸ì…˜ ì €ì¥
                    filename = save_session_to_json()
                    if filename:
                        st.success(f"í† ë¡ ì´ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

                st.session_state.active = False
                st.session_state.topic = ""
                st.session_state.messages = []
                st.rerun()

            if save_button:
                filename = save_session_to_json()
                if filename:
                    st.success(f"í† ë¡ ì´ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    else:
        st.info(
            "â–¶ï¸ í† ë¡  ì‹œì‘ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìƒˆë¡œìš´ í† ë¡ ì„ ì‹œì‘í•˜ê±°ë‚˜, ì´ì „ í† ë¡ ì„ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”!"
        )


if __name__ == "__main__":
    main()


def show_api_status():
    """API ì„¤ì • ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ"""
    if not st.session_state.ai_generator.initialization_successful:
        st.warning(
            """
        âš ï¸ AI ì‘ë‹µ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
        
        í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ AI: {available_models}
        
        API í‚¤ ì„¤ì • ë°©ë²•:
        1. OpenAI API í‚¤: https://platform.openai.com
        2. Anthropic API í‚¤: https://console.anthropic.com
        3. Gemini API í‚¤: https://makersuite.google.com/app/apikey
        
        ì„¤ì •ëœ API í‚¤ì— í•´ë‹¹í•˜ëŠ” AIë§Œ í† ë¡ ì— ì°¸ì—¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """.format(
                available_models=(
                    ", ".join(st.session_state.ai_generator.available_models)
                    if st.session_state.ai_generator.available_models
                    else "ì—†ìŒ"
                )
            )
        )


class AIResponseGenerator:
    """AI ì‘ë‹µ ìƒì„±ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        self.initialization_successful = False
        self.available_models = []

        try:
            # OpenAI API ì´ˆê¸°í™” ì‹œë„
            if "OPENAI_KEY" in st.secrets:
                self.openai_client = OpenAI(api_key=st.secrets["OPENAI_KEY"])
                self.available_models.append("ì§€í”¼")

            # Anthropic API ì´ˆê¸°í™” ì‹œë„
            if "ANTHROPIC_KEY" in st.secrets:
                self.anthropic_client = Anthropic(api_key=st.secrets["ANTHROPIC_KEY"])
                self.available_models.append("ë¡œë“œ")

            # Gemini API ì´ˆê¸°í™” ì‹œë„
            if "GEMINI_KEY" in st.secrets:
                genai.configure(api_key=st.secrets["GEMINI_KEY"])
                self.available_models.append("ì¬ë¯¼")

            if self.available_models:
                self.initialization_successful = True
            else:
                st.warning("âš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ì‘ë‹µ ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"API ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            self.initialization_successful = False

    def generate_response(self, ai_name, topic, messages):
        """AI ë³„ ì‘ë‹µ ìƒì„±"""
        if not self.initialization_successful:
            return "ğŸ”’ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        if ai_name not in self.available_models:
            return f"ğŸ”’ {ai_name}ì˜ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        try:
            model_config = AI_MODELS[ai_name]
            prompt = self.format_prompt(messages, topic)

            # ê° AI ëª¨ë¸ë³„ ì‘ë‹µ ìƒì„± ë¡œì§...

        except Exception as e:
            st.error(f"{ai_name} ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"[ì‹œìŠ¤í…œ] {ai_name}ì˜ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
