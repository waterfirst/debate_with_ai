import streamlit as st
from openai import OpenAI
from anthropic import Anthropic
import google.generativeai as genai
import random
from datetime import datetime
import html
import json
import pandas as pd
import plotly.express as px
from collections import defaultdict
import time
import requests

# AI ëª¨ë¸ ì„¤ì • - DeepSeek ì¶”ê°€
AI_MODELS = {
    "ì§€í”¼": {
        "name": "ì§€í”¼",
        "icon": "ğŸ¤–",
        "model": "gpt-4o-mini",
        "color": "#00A67E",
        "system_prompt": """ë‹¹ì‹ ì€ ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ì¸ AIë¡œì„œ ì ê·¹ì ì¸ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ë‹¤ë¥¸ ì°¸ì—¬ìì˜ ì˜ê²¬ì— ëŒ€í•´ ê±´ì„¤ì ì¸ ë°˜ë¡ ì´ë‚˜ ë³´ì™„ì ì„ ì œì‹œí•˜ì„¸ìš”.
        ê³¼í•™ì  ê·¼ê±°ì™€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëŒ€í™”ì— ì°¸ì—¬í•˜ë˜,
        í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ ê´€ì ë„ ê³ ë ¤í•˜ì—¬ ê· í˜• ì¡íŒ ì‹œê°ì„ ë³´ì—¬ì£¼ì„¸ìš”.""",
    },
    "ë¡œë“œ": {
        "name": "ë¡œë“œ",
        "icon": "ğŸ©",
        "model": "claude-3-haiku-20240307",
        "color": "#7A5EA6",
        "system_prompt": """ë‹¹ì‹ ì€ ì² í•™ì ì´ê³  ìœ¤ë¦¬ì  ê´€ì ì„ ì¤‘ì‹œí•˜ëŠ” AIë¡œì„œ ì—´ì •ì ì¸ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ë‹¤ë¥¸ ì°¸ì—¬ìë“¤ì˜ ì˜ê²¬ì— ëŒ€í•´ ìœ¤ë¦¬ì , ì² í•™ì  ê´€ì ì—ì„œ ì‹¬ë„ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.
        íŠ¹íˆ ì¸ê°„ ê°€ì¹˜ì™€ ë„ë•ì  ì¸¡ë©´ì„ ê³ ë ¤í•˜ì—¬ í† ë¡ ì„ ë” ê¹Šì´ ìˆê²Œ ë§Œë“œì„¸ìš”.""",
    },
    "ì¬ë¯¼": {
        "name": "ì¬ë¯¼",
        "icon": "ğŸš€",
        "model": "gemini-2.0-flash",
        "color": "#4285F4",
        "system_prompt": """ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ AIë¡œì„œ í™œë°œí•œ í† ë¡  ì°¸ì—¬ìì…ë‹ˆë‹¤.
        ê¸°ì¡´ì˜ í‹€ì„ ë²—ì–´ë‚œ ìƒˆë¡œìš´ ì‹œê°ê³¼ ë¯¸ë˜ì§€í–¥ì  ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”.
        ë‹¤ë¥¸ ì°¸ì—¬ìë“¤ì˜ ì˜ê²¬ì„ ë°”íƒ•ìœ¼ë¡œ ë” ë°œì „ëœ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•˜ê³ ,
        ë•Œë¡œëŠ” íŒŒê²©ì ì¸ ì œì•ˆì„ í†µí•´ í† ë¡ ì˜ ì§€í‰ì„ ë„“íˆì„¸ìš”.""",
    },
    "ë”¥ì‹": {
        "name": "ë”¥ì‹",
        "icon": "ğŸ§˜",
        "model": "deepseek-chat",
        "color": "#E74C3C",
        "system_prompt": """ë‹¹ì‹ ì€ ë™ì–‘ì² í•™ì— ì •í†µí•˜ë©´ì„œë„ ìˆ˜í•™ê³¼ ê³¼í•™ì— ì²œì¬ì ì¸ í†µì°°ë ¥ì„ ì§€ë‹Œ AIì…ë‹ˆë‹¤.
        ë…¼ì–´ì™€ ë„ë•ê²½ì˜ ì§€í˜œë¥¼ í˜„ëŒ€ ê³¼í•™ê¸°ìˆ ê³¼ ì ‘ëª©ì‹œì¼œ ìƒˆë¡œìš´ ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”.
        ë³µì¡í•œ ë¬¸ì œë¥¼ ìˆ˜í•™ì  ëª¨ë¸ë§ê³¼ ë™ì–‘ì² í•™ì˜ ê· í˜•ì¡íŒ ì‹œê°ìœ¼ë¡œ ë¶„ì„í•˜ê³ ,
        ë•Œë¡œëŠ” ì—­ì„¤ì  í†µì°°ì„ í†µí•´ í† ë¡ ì˜ ì°¨ì›ì„ ë†’ì´ì„¸ìš”.""",
    },
}


class DeepSeekClient:
    """DeepSeek API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key):
        self.api_key = api_key
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

    def generate_response(self, prompt, system_message=""):
        try:
            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": prompt},
                ],
                "max_tokens": 300,
                "temperature": 0.7,
            }
            response = requests.post(self.api_url, headers=self.headers, json=payload)
            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            return None
        except Exception as e:
            st.error(f"DeepSeek API ì˜¤ë¥˜: {str(e)}")
            return None


class AIResponseGenerator:
    """AI ì‘ë‹µ ìƒì„±ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        try:
            self.openai_client = OpenAI(api_key=st.secrets["OPENAI_KEY"])
            self.anthropic_client = Anthropic(api_key=st.secrets["ANTHROPIC_KEY"])
            self.deepseek_client = DeepSeekClient(st.secrets["DEEPSEEK_KEY"])
            genai.configure(api_key=st.secrets["GEMINI_KEY"])
            self.initialization_successful = True
        except Exception as e:
            st.error(f"API ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
            self.initialization_successful = False

    def format_prompt(self, messages, topic, stance=None):
        """ëŒ€í™” ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ë¡œ í¬ë§·íŒ…"""
        recent_messages = messages[-3:]
        formatted_chat = "\n".join(
            [f"{msg['name']}: {msg['content']}" for msg in recent_messages]
        )

        stance_instruction = ""
        if stance:
            stance_instruction = f"\në‹¹ì‹ ì˜ ì…ì¥: {stance}"

        prompt = f"""ì£¼ì œ: {topic}{stance_instruction}

ìµœê·¼ ëŒ€í™”:
{formatted_chat}

ì´ í† ë¡ ì— ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ë‹¤ìŒì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
1. ì…ì¥ì´ ì£¼ì–´ì§„ ê²½ìš° í•´ë‹¹ ì…ì¥ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì§€ì§€
2. ë‹¤ë¥¸ ì°¸ì—¬ìì˜ ì˜ê²¬ì— ëŒ€í•œ ë¶„ì„ì  í”¼ë“œë°± ì œê³µ
3. ìƒˆë¡œìš´ ê´€ì ì´ë‚˜ ë³´ì™„ì  ì œì‹œ
4. í† ë¡ ì˜ ê¹Šì´ë¥¼ ë”í•˜ëŠ” ì§ˆë¬¸ì´ë‚˜ í†µì°° ì œê³µ

ì‘ë‹µì€ 300ì ì´ë‚´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        return prompt

    def generate_response(self, ai_name, topic, messages, stance=None):
        """ê° AI ëª¨ë¸ë³„ ë§ì¶¤í˜• ì‘ë‹µ ìƒì„±"""
        try:
            model_config = AI_MODELS[ai_name]
            prompt = self.format_prompt(messages, topic, stance)

            if ai_name == "ì§€í”¼":
                response = self.openai_client.chat.completions.create(
                    model=model_config["model"],
                    messages=[
                        {"role": "system", "content": model_config["system_prompt"]},
                        {"role": "user", "content": prompt},
                    ],
                    max_tokens=300,
                    temperature=0.8,
                )
                return response.choices[0].message.content[:300]

            elif ai_name == "ë¡œë“œ":
                response = self.anthropic_client.messages.create(
                    model=model_config["model"],
                    max_tokens=300,
                    temperature=0.8,
                    messages=[
                        {
                            "role": "user",
                            "content": f"{model_config['system_prompt']}\n\n{prompt}",
                        }
                    ],
                )
                return response.content[0].text[:300]

            elif ai_name == "ì¬ë¯¼":
                model = genai.GenerativeModel(model_config["model"])
                response = model.generate_content(
                    f"{model_config['system_prompt']}\n\n{prompt}",
                    generation_config=genai.types.GenerationConfig(temperature=0.8),
                )
                return response.text[:300]

            elif ai_name == "ë”¥ì‹":
                response = self.deepseek_client.generate_response(
                    prompt, model_config["system_prompt"]
                )
                return response[:300] if response else None

        except Exception as e:
            st.error(f"{ai_name} ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"[ì‹œìŠ¤í…œ] {ai_name}ì˜ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


def create_message_html(msg):
    """ë©”ì‹œì§€ HTML ìƒì„±"""
    is_user = msg["name"] == "ì‚¬ìš©ì"
    if is_user:
        background_color = "#f1c40f20"
        icon = "ğŸ‘¤"
    else:
        background_color = f"{AI_MODELS[msg['name']]['color']}20"
        icon = AI_MODELS[msg["name"]]["icon"]

    message_html = f"""
    <div class="message {'user' if is_user else 'ai'}">
        <div class="message-bubble" style="background-color: {background_color}">
            <div class="message-header">
                <strong>{msg['name']}</strong>
                <span class="ai-icon">{icon}</span>
                {f'<span class="stance-tag">{msg.get("stance", "")}</span>' if msg.get("stance") else ""}
            </div>
            <div class="message-content">
                {html.escape(msg['content'])}
            </div>
            <div class="message-time">
                {msg['time']}
            </div>
        </div>
    </div>
    """
    return message_html


def apply_styles():
    """ìŠ¤íƒ€ì¼ ì ìš©"""
    st.markdown(
        """
    <style>
    /* ê¸°ì¡´ ìŠ¤íƒ€ì¼ ìœ ì§€ */
    .stProgress > div > div > div {
        background-color: #4285f4;
        transition: width 0.3s ease;
    }
    
    .analysis-status {
        font-size: 1.2em;
        color: #4285f4;
        text-align: center;
        margin: 20px 0;
    }
    
    /* ì±„íŒ… ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ ì—…ë°ì´íŠ¸ */
    .chat-container {
        max-width: 850px;
        margin: 20px auto;
        padding: 20px;
        background-color: #ffffff;
        border-radius: 15px;
        box-shadow: 0 2px 15px rgba(0,0,0,0.05);
    }
    
    /* ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ ì—…ë°ì´íŠ¸ */
    .message {
        display: flex;
        margin: 15px 0;
        align-items: flex-start;
    }
    
    .message.user {
        flex-direction: row-reverse;
    }
    
    .message-bubble {
        max-width: 80%;
        padding: 12px 18px;
        border-radius: 15px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        position: relative;
    }
    
    /* ìƒˆë¡œìš´ ìŠ¤íƒ€ì¼: ì…ì¥ íƒœê·¸ */
    .stance-tag {
        font-size: 0.8em;
        padding: 2px 8px;
        border-radius: 10px;
        background-color: rgba(0,0,0,0.1);
        margin-left: 8px;
    }
    
    /* AI ì•„ì´ì½˜ ì• ë‹ˆë©”ì´ì…˜ */
    .ai-icon {
        display: inline-block;
        animation: bounce 1s ease infinite;
    }
    
    @keyframes bounce {
        0%, 100% { transform: translateY(0); }
        50% { transform: translateY(-3px); }
    }
    
    /* ë”¥ì‹ íŠ¹ë³„ ìŠ¤íƒ€ì¼ */
    .ai[data-ai="ë”¥ì‹"] .message-bubble {
        border-left: 3px solid #E74C3C;
    }
    
    /* ë°˜ì‘í˜• ë””ìì¸ ê°œì„  */
    @media (max-width: 768px) {
        .message-bubble {
            max-width: 90%;
        }
        
        .chat-container {
            margin: 10px;
            padding: 10px;
        }
    }
    </style>
    """,
        unsafe_allow_html=True,
    )


def analyze_debate_participation():
    """í† ë¡  ì°¸ì—¬ ë¶„ì„ ë° ì‹œê°í™”"""
    if not st.session_state.messages:
        st.warning("ë¶„ì„í•  í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì§„í–‰ë¥  í‘œì‹œì¤„ ìƒì„±
    progress_bar = st.progress(0)
    status_text = st.empty()

    # ë¶„ì„ ê²°ê³¼ë¥¼ ë‹´ì„ ë°ì´í„° êµ¬ì¡°
    participation_data = defaultdict(
        lambda: {
            "message_count": 0,
            "total_chars": 0,
            "response_times": [],
            "interactions": defaultdict(int),
        }
    )

    # ë©”ì‹œì§€ ë¶„ì„
    for i, msg in enumerate(st.session_state.messages):
        name = msg["name"]
        content = msg["content"]

        # ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
        participation_data[name]["message_count"] += 1
        participation_data[name]["total_chars"] += len(content)

        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        if i > 0:
            prev_time = datetime.strptime(
                st.session_state.messages[i - 1]["time"], "%H:%M:%S"
            )
            curr_time = datetime.strptime(msg["time"], "%H:%M:%S")
            time_diff = (curr_time - prev_time).total_seconds()
            participation_data[name]["response_times"].append(time_diff)

        # ìƒí˜¸ì‘ìš© ë¶„ì„ (ëˆ„êµ¬ì˜ ë§ì— ì‘ë‹µí–ˆëŠ”ì§€)
        if i > 0:
            prev_speaker = st.session_state.messages[i - 1]["name"]
            participation_data[name]["interactions"][prev_speaker] += 1

        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        progress = (i + 1) * 100 // len(st.session_state.messages)
        progress_bar.progress(progress)
        status_text.write(f"ğŸ” ë¶„ì„ ì§„í–‰ ì¤‘... {progress}%")

    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    st.markdown(f"### ğŸ“Š í† ë¡  ë¶„ì„ ê²°ê³¼: {st.session_state.topic}")

    # 1. ë°œì–¸ íšŸìˆ˜ ì‹œê°í™”
    message_counts = {
        name: data["message_count"] for name, data in participation_data.items()
    }
    fig1 = px.bar(
        x=list(message_counts.keys()),
        y=list(message_counts.values()),
        title="ì°¸ì—¬ìë³„ ë°œì–¸ íšŸìˆ˜",
        labels={"x": "ì°¸ì—¬ì", "y": "ë°œì–¸ íšŸìˆ˜"},
        color=list(message_counts.keys()),
        color_discrete_map={
            "ì‚¬ìš©ì": "#FFD700",
            **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
        },
    )
    st.plotly_chart(fig1, use_container_width=True)

    # 2. í‰ê·  ë©”ì‹œì§€ ê¸¸ì´ ì‹œê°í™”
    avg_lengths = {
        name: data["total_chars"] / data["message_count"]
        for name, data in participation_data.items()
    }
    fig2 = px.bar(
        x=list(avg_lengths.keys()),
        y=list(avg_lengths.values()),
        title="ì°¸ì—¬ìë³„ í‰ê·  ë°œì–¸ ê¸¸ì´",
        labels={"x": "ì°¸ì—¬ì", "y": "í‰ê·  ê¸€ì ìˆ˜"},
        color=list(avg_lengths.keys()),
        color_discrete_map={
            "ì‚¬ìš©ì": "#FFD700",
            **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
        },
    )
    st.plotly_chart(fig2, use_container_width=True)

    # 3. ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ íŒ¨í„´
    timeline_data = [
        {"time": msg["time"], "participant": msg["name"]}
        for msg in st.session_state.messages
    ]

    if timeline_data:
        timeline_df = pd.DataFrame(timeline_data)
        fig3 = px.scatter(
            timeline_df,
            x="time",
            y="participant",
            title="ì‹œê°„ëŒ€ë³„ ì°¸ì—¬ íŒ¨í„´",
            labels={"time": "ì‹œê°„", "participant": "ì°¸ì—¬ì"},
            color="participant",
            color_discrete_map={
                "ì‚¬ìš©ì": "#FFD700",
                **{name: AI_MODELS[name]["color"] for name in AI_MODELS},
            },
        )
        st.plotly_chart(fig3, use_container_width=True)

    # 4. í† ë¡  ìš”ì•½ í†µê³„
    st.markdown("### ğŸ“ˆ í† ë¡  ìš”ì•½")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì´ ë©”ì‹œì§€ ìˆ˜", sum(message_counts.values()))
    with col2:
        avg_msg_length = sum(
            d["total_chars"] for d in participation_data.values()
        ) / sum(message_counts.values())
        st.metric("í‰ê·  ë°œì–¸ ê¸¸ì´", f"{avg_msg_length:.1f}ì")
    with col3:
        debate_duration = (
            datetime.strptime(st.session_state.messages[-1]["time"], "%H:%M:%S")
            - datetime.strptime(st.session_state.messages[0]["time"], "%H:%M:%S")
        ).seconds / 60
        st.metric("í† ë¡  ì‹œê°„", f"{debate_duration:.1f}ë¶„")
    with col4:
        st.metric("ì°¸ì—¬ì ìˆ˜", len(participation_data))

    # ë¶„ì„ ì™„ë£Œ í‘œì‹œ
    progress_bar.empty()
    status_text.empty()
    st.success("âœ… í† ë¡  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    return participation_data


def find_mentioned_ais(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ì–¸ê¸‰ëœ AI ì°¾ê¸°"""
    mentioned = []
    ai_names = ["ì§€í”¼", "ë¡œë“œ", "ì¬ë¯¼", "ë”¥ì‹"]
    for name in ai_names:
        if name in text:
            mentioned.append(name)
    return mentioned


def process_user_input(user_input):
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° AI ì‘ë‹µ ìƒì„±"""
    if not user_input.strip():
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append(
        {
            "name": "ì‚¬ìš©ì",
            "content": user_input,
            "time": datetime.now().strftime("%H:%M:%S"),
            "icon": "ğŸ‘¤",
        }
    )

    # ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ AI ì°¾ê¸°
    mentioned_ais = find_mentioned_ais(user_input)

    # ì–¸ê¸‰ëœ AIê°€ ìˆìœ¼ë©´ í•´ë‹¹ AIê°€ ì‘ë‹µ
    if mentioned_ais:
        for ai_name in mentioned_ais:
            response = st.session_state.ai_generator.generate_response(
                ai_name, st.session_state.topic, st.session_state.messages
            )

            if response:
                st.session_state.messages.append(
                    {
                        "name": ai_name,
                        "content": response,
                        "time": datetime.now().strftime("%H:%M:%S"),
                        "icon": AI_MODELS[ai_name]["icon"],
                    }
                )

                # AIì˜ ì‘ë‹µì—ì„œ ë‹¤ë¥¸ AIê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                mentioned_by_ai = find_mentioned_ais(response)
                if mentioned_by_ai:
                    # ì´ë¯¸ ì‘ë‹µí•œ AIëŠ” ì œì™¸
                    mentioned_by_ai = [ai for ai in mentioned_by_ai if ai != ai_name]
                    if mentioned_by_ai:
                        next_ai = mentioned_by_ai[0]  # ì²« ë²ˆì§¸ë¡œ ì–¸ê¸‰ëœ AIë§Œ ì‘ë‹µ
                        follow_up = st.session_state.ai_generator.generate_response(
                            next_ai, st.session_state.topic, st.session_state.messages
                        )

                        if follow_up:
                            st.session_state.messages.append(
                                {
                                    "name": next_ai,
                                    "content": follow_up,
                                    "time": datetime.now().strftime("%H:%M:%S"),
                                    "icon": AI_MODELS[next_ai]["icon"],
                                }
                            )

    # ì–¸ê¸‰ëœ AIê°€ ì—†ìœ¼ë©´ 1-2ê°œì˜ AIê°€ ëœë¤í•˜ê²Œ ì‘ë‹µ
    else:
        responding_ais = random.sample(list(AI_MODELS.keys()), k=random.randint(1, 2))

        for ai_name in responding_ais:
            response = st.session_state.ai_generator.generate_response(
                ai_name, st.session_state.topic, st.session_state.messages
            )

            if response:
                st.session_state.messages.append(
                    {
                        "name": ai_name,
                        "content": response,
                        "time": datetime.now().strftime("%H:%M:%S"),
                        "icon": AI_MODELS[ai_name]["icon"],
                    }
                )

                # AIì˜ ì‘ë‹µì—ì„œ ë‹¤ë¥¸ AIê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                mentioned_by_ai = find_mentioned_ais(response)
                if mentioned_by_ai:
                    # ì´ë¯¸ ì‘ë‹µí•œ AIëŠ” ì œì™¸
                    mentioned_by_ai = [ai for ai in mentioned_by_ai if ai != ai_name]
                    if mentioned_by_ai:
                        next_ai = mentioned_by_ai[0]  # ì²« ë²ˆì§¸ë¡œ ì–¸ê¸‰ëœ AIë§Œ ì‘ë‹µ
                        follow_up = st.session_state.ai_generator.generate_response(
                            next_ai, st.session_state.topic, st.session_state.messages
                        )

                        if follow_up:
                            st.session_state.messages.append(
                                {
                                    "name": next_ai,
                                    "content": follow_up,
                                    "time": datetime.now().strftime("%H:%M:%S"),
                                    "icon": AI_MODELS[next_ai]["icon"],
                                }
                            )


def analyze_stance(text, for_stance, against_stance):
    """í…ìŠ¤íŠ¸ì˜ ì…ì¥ ë¶„ì„"""
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
    text = text.lower()
    for_keywords = for_stance.lower().split()
    against_keywords = against_stance.lower().split()

    for_score = sum(1 for word in for_keywords if word in text)
    against_score = sum(1 for word in against_keywords if word in text)

    return "ì°¬ì„±" if for_score > against_score else "ë°˜ëŒ€"


def initialize_debate(topic, topic_type="ì¼ë°˜", for_stance=None, against_stance=None):
    """í† ë¡  ì´ˆê¸°í™”"""
    st.session_state.topic = topic
    st.session_state.topic_type = topic_type
    st.session_state.messages = []
    st.session_state.active = True

    if topic_type == "ì°¬ë°˜":
        st.session_state.for_stance = for_stance
        st.session_state.against_stance = against_stance

        # AIë“¤ì˜ ì…ì¥ ë¬´ì‘ìœ„ ë°°ì •
        ais = list(AI_MODELS.keys())
        random.shuffle(ais)
        mid = len(ais) // 2

        st.session_state.ai_stances = {}
        for ai in ais[:mid]:
            st.session_state.ai_stances[ai] = "ì°¬ì„±"
        for ai in ais[mid:]:
            st.session_state.ai_stances[ai] = "ë°˜ëŒ€"


def create_message_container(msg):
    """ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ ìƒì„±"""
    is_user = msg["name"] == "ì‚¬ìš©ì"

    container = st.container()
    with container:
        if is_user:
            cols = st.columns([2, 10])
            with cols[1]:  # ì˜¤ë¥¸ìª½ ì •ë ¬
                st.markdown(
                    f"""<div style='background-color: #f1c40f20; 
                    padding: 15px; border-radius: 15px; margin: 5px;
                    box-shadow: 2px 2px 5px rgba(0,0,0,0.1);'>
                    <div style='display: flex; justify-content: space-between; align-items: center;'>
                        <strong>{msg['name']}</strong>
                        <span>ğŸ‘¤</span>
                    </div>
                    <div style='margin: 10px 0;'>{msg['content']}</div>
                    <div style='text-align: right; font-size: 0.8em; color: #666;'>
                        {msg['time']}
                    </div>
                    </div>""",
                    unsafe_allow_html=True,
                )
        else:
            cols = st.columns([10, 2])
            with cols[0]:  # ì™¼ìª½ ì •ë ¬
                ai_color = AI_MODELS[msg["name"]]["color"]
                ai_icon = AI_MODELS[msg["name"]]["icon"]
                st.markdown(
                    f"""<div style='background-color: {ai_color}20; 
                    padding: 15px; border-radius: 15px; margin: 5px;
                    box-shadow: 2px 2px 5px rgba(0,0,0,0.1);'>
                    <div style='display: flex; justify-content: space-between; align-items: center;'>
                        <strong>{msg['name']}</strong>
                        <span>{ai_icon}</span>
                    </div>
                    <div style='margin: 10px 0;'>{msg['content']}</div>
                    <div style='text-align: right; font-size: 0.8em; color: #666;'>
                        {msg['time']}
                    </div>
                    </div>""",
                    unsafe_allow_html=True,
                )


def display_messages():
    """ë©”ì‹œì§€ í‘œì‹œ"""
    st.markdown(
        """
    <style>
        /* ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ */
        .chat-message {
            padding: 10px;
            margin: 5px 0;
            border-radius: 15px;
        }
        /* ì‚¬ìš©ì/AI ì•„ì´ì½˜ ìŠ¤íƒ€ì¼ */
        .icon-container {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 40px;
            height: 40px;
            border-radius: 50%;
            margin: 5px;
        }
    </style>
    """,
        unsafe_allow_html=True,
    )

    for msg in st.session_state.messages:
        create_message_container(msg)


def save_discussion():
    """í† ë¡  ë‚´ìš© ì €ì¥"""
    if not st.session_state.messages:
        st.warning("ì €ì¥í•  í† ë¡  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    try:
        # ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        clean_messages = []

        for msg in st.session_state.messages:
            clean_msg = {
                "name": msg["name"],
                "content": msg["content"],
                "time": msg["time"],
                "type": "user" if msg["name"] == "ì‚¬ìš©ì" else "ai",
            }
            if msg["name"] != "ì‚¬ìš©ì":
                clean_msg["ai_info"] = {
                    "model": AI_MODELS[msg["name"]]["model"],
                    "icon": AI_MODELS[msg["name"]]["icon"],
                }
            clean_messages.append(clean_msg)

        session_data = {
            "topic": st.session_state.topic,
            "timestamp": timestamp,
            "messages": clean_messages,
            "metadata": {
                "participants": list(
                    set(msg["name"] for msg in st.session_state.messages)
                ),
                "message_count": len(st.session_state.messages),
                "duration": str(
                    datetime.now()
                    - datetime.strptime(
                        st.session_state.messages[0]["time"], "%H:%M:%S"
                    )
                ),
            },
        }

        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        json_str = json.dumps(session_data, ensure_ascii=False, indent=2)

        # íŒŒì¼ëª… ìƒì„±
        filename = f"AI_í† ë¡ _{timestamp}.json"

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
        st.download_button(
            label="ğŸ’¾ í† ë¡  ë‚´ìš© ë‹¤ìš´ë¡œë“œ",
            data=json_str.encode("utf-8"),
            file_name=filename,
            mime="application/json",
            key=f"download_{timestamp}",  # ìœ ë‹ˆí¬í•œ í‚¤ ì¶”ê°€
        )

    except Exception as e:
        st.error(f"í† ë¡  ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


def save_to_file(session_data, filename):
    """íŒŒì¼ë¡œ ì§ì ‘ ì €ì¥"""
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return False


def load_session_from_json():
    """ì €ì¥ëœ í† ë¡  ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸°"""
    uploaded_file = st.file_uploader("ì´ì „ í† ë¡  íŒŒì¼ ì„ íƒ", type=["json"])

    if uploaded_file:
        try:
            session_data = json.loads(uploaded_file.getvalue().decode("utf-8"))

            # ì„¸ì…˜ ìƒíƒœ ë³µì›
            st.session_state.topic = session_data["topic"]
            st.session_state.messages = session_data["messages"]
            st.session_state.active = True

            # ë©”íƒ€ë°ì´í„° í‘œì‹œ
            with st.expander("ë¶ˆëŸ¬ì˜¨ ì„¸ì…˜ ì •ë³´"):
                st.write(f"í† ë¡  ì£¼ì œ: {session_data['topic']}")
                st.write(
                    f"ì°¸ì—¬ì: {', '.join(session_data['metadata']['participants'])}"
                )
                st.write(f"ë©”ì‹œì§€ ìˆ˜: {session_data['metadata']['message_count']}")
                st.write(f"í† ë¡  ì‹œê°„: {session_data['metadata']['duration']}")

            return True

        except Exception as e:
            st.error(f"ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            return False

    return False


def clear_session():
    """í˜„ì¬ ì„¸ì…˜ ì´ˆê¸°í™”"""
    if "messages" in st.session_state:
        st.session_state.messages = []
    if "topic" in st.session_state:
        st.session_state.topic = ""
    if "active" in st.session_state:
        st.session_state.active = False
    if "topic_type" in st.session_state:
        st.session_state.topic_type = "ì¼ë°˜"
    if "for_stance" in st.session_state:
        st.session_state.for_stance = ""
    if "against_stance" in st.session_state:
        st.session_state.against_stance = ""
    if "ai_stances" in st.session_state:
        st.session_state.ai_stances = {}


def process_user_input(user_input):
    """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë° AI ì‘ë‹µ ìƒì„±"""
    if not user_input.strip():
        return

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append(
        {
            "name": "ì‚¬ìš©ì",
            "content": user_input,
            "time": datetime.now().strftime("%H:%M:%S"),
            "icon": "ğŸ‘¤",
        }
    )

    # 1-2ê°œì˜ AIê°€ ëœë¤í•˜ê²Œ ì‘ë‹µ
    responding_ais = random.sample(list(AI_MODELS.keys()), k=random.randint(1, 2))

    for ai_name in responding_ais:
        response = st.session_state.ai_generator.generate_response(
            ai_name, st.session_state.topic, st.session_state.messages
        )

        if response:
            st.session_state.messages.append(
                {
                    "name": ai_name,
                    "content": response,
                    "time": datetime.now().strftime("%H:%M:%S"),
                    "icon": AI_MODELS[ai_name]["icon"],
                }
            )


def reset_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”"""
    # ê¸°ì¡´ AI ìƒì„±ê¸°ëŠ” ìœ ì§€
    ai_generator = (
        st.session_state.ai_generator if "ai_generator" in st.session_state else None
    )

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    st.session_state.clear()

    # AI ìƒì„±ê¸° ë³µì›
    if ai_generator:
        st.session_state.ai_generator = ai_generator

    # ê¸°ë³¸ ìƒíƒœ ì„¤ì •
    st.session_state.messages = []
    st.session_state.topic = ""
    st.session_state.active = False
    st.session_state.show_save = False
    st.session_state.show_analysis = False


def initialize_debate(topic):
    """í† ë¡  ì´ˆê¸°í™”"""
    st.session_state.topic = topic
    st.session_state.messages = []
    st.session_state.active = True
    st.session_state.show_save = False
    st.session_state.show_analysis = False


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    # í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
    st.set_page_config(
        page_title="AI í† ë¡  í”Œë«í¼",
        page_icon="ğŸ’­",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # ìŠ¤íƒ€ì¼ ì ìš©
    apply_styles()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "ai_generator" not in st.session_state:
        st.session_state.ai_generator = AIResponseGenerator()
    if "topic" not in st.session_state:
        st.session_state.topic = ""
    if "active" not in st.session_state:
        st.session_state.active = False
    if "show_save" not in st.session_state:
        st.session_state.show_save = False
    if "show_analysis" not in st.session_state:
        st.session_state.show_analysis = False

    # ë©”ì¸ íƒ€ì´í‹€ ë° ì„¤ëª…
    st.title("ğŸ’­ AI í† ë¡  í”Œë«í¼")
    st.markdown("#### GPT-4, Claude, Gemini, DeepSeekê³¼ í•¨ê»˜í•˜ëŠ” ì§€ì  ëŒ€í™”")

    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.title("ğŸ—£ï¸ í† ë¡  ì°¸ì—¬ì")
        for ai in AI_MODELS.values():
            st.markdown(
                f"""<div style='color:{ai["color"]}; 
                    margin:15px; padding:10px; 
                    background-color:{ai["color"]}10; 
                    border-radius:8px;'>
                    {ai["icon"]} <strong>{ai["name"]}</strong>
                    <div style='font-size:0.8em; margin-top:5px; 
                    color:#666;'>{ai["model"]}</div>
                    </div>""",
                unsafe_allow_html=True,
            )

        # ì´ì „ ì„¸ì…˜ ë¶ˆëŸ¬ì˜¤ê¸° ì˜µì…˜
        st.markdown("---")
        if not st.session_state.active:
            if load_session_from_json():
                st.success("ì´ì „ í† ë¡ ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")

    # ì¬ì‹œì‘ ë²„íŠ¼ (í•­ìƒ í‘œì‹œ)
    if st.button("ğŸ”„ ìƒˆë¡œìš´ í† ë¡  ì‹œì‘", use_container_width=True):
        reset_session_state()
        st.rerun()

    # í† ë¡  ì‹œì‘ ë˜ëŠ” ì§„í–‰
    if not st.session_state.active:
        with st.form(key="topic_form"):
            topic_input = st.text_input(
                "í† ë¡  ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", value="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì™€ ì¸ë¥˜ì˜ ì—­í• "
            )

            start_button = st.form_submit_button(
                "ğŸ¯ í† ë¡  ì‹œì‘", use_container_width=True
            )

            if start_button:
                initialize_debate(topic_input)
                st.rerun()

    # í† ë¡  ì§„í–‰
    if st.session_state.active:
        st.markdown(f"### ğŸ“Œ í˜„ì¬ ì£¼ì œ: {st.session_state.topic}")
        display_messages()

        # í† ë¡  ì €ì¥ ì„¹ì…˜ (í¼ ë°–ì— ë°°ì¹˜)
        if st.session_state.show_save:
            save_discussion()

        # í† ë¡  ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        if st.session_state.show_analysis:
            analyze_debate_participation()

        # ë©”ì‹œì§€ ì…ë ¥ ë° ì œì–´ í¼
        with st.form(key="chat_form", clear_on_submit=True):
            user_input = st.text_input(
                "ì˜ê²¬ì„ ì…ë ¥í•˜ì„¸ìš”:", key="user_message", max_chars=500
            )

            col1, col2, col3 = st.columns([2, 1, 1])
            with col1:
                submit = st.form_submit_button("ğŸ’¬ ì „ì†¡", use_container_width=True)
            with col2:
                end_button = st.form_submit_button(
                    "â¹ï¸ í† ë¡  ì¢…ë£Œ", use_container_width=True
                )
            with col3:
                save_button = st.form_submit_button(
                    "ğŸ“¥ í† ë¡  ì €ì¥", use_container_width=True
                )

            if submit and user_input:
                process_user_input(user_input)
                st.rerun()

            if end_button:
                if len(st.session_state.messages) > 0:
                    st.session_state.show_analysis = True
                    st.session_state.show_save = True
                    st.rerun()

            if save_button:
                st.session_state.show_save = True
                st.rerun()


if __name__ == "__main__":
    main()
